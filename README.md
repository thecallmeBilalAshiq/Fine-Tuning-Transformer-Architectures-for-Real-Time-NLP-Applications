# Fine-Tuning-Transformer-Architectures-for-Real-Time-NLP-Applications
This project fine-tunes three Transformer architectures (BERT, GPT-2, T5/BART) for real-time NLP tasks like sentiment classification, code generation, and text summarization. The implementation includes a Streamlit/Gradio interface, evaluation metrics, and a blog post summarizing the results.
